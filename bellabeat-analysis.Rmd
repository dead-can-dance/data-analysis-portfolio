---
title: "Proyecto de análisis de datos de Bellabeat"
author: "Fabián Barragán Barriga"
output:
  html_document:
    df_print: paged
---
# 1. Resumen de tarea empresarial

## Introducción y Contexto empresarial
Bellabeat es una empresa fabricante de productos de alta tecnología orientados a la salud de la mujer. 
Bellabeat es una empresa pequeña exitosa, pero tiene el potencial para convertirse en un actor más grande en el 
mercado global de dispositivos inteligentes.

### 1.1 Hipótesis inicial
Una de las principales cofundadoras de la empresa (Urška Sršen) tiene la hipótesis inicial que si se analizaran datos de la 
actividad física de los dispositivos inteligentes de podría desplegar nuevas oportunidades de negocio para la empresa.

### 1.2 Actores
1. **Urška Sršen**: confundadora y directora creativa de Bellabeat
2. **Sando Mur**: matemático, confundador y ejecutivo de la empresa
3. **Equipo de análisis computacional de datos de marketing de Bellabeat**

### 1.3 Recursos tecnológicos disponibles
1. **App Bellabeat**: aplicación que ayuda a los usuarios a comprender sus hábitos actuales para tomar decisiones salusables, esto se logra con la recopilación de datos sobre *Actividad física*, *sueño*,*estrés*,*ciclo menstrual*, _hábitos de conciencia_.Esta app está conectada a los gadgets. 

2. **Leaf**: gadget (pulsera,collar,clip) conectada a la app de bellabeat para recopilar datos sobre 
_Actividad física_, _sueño_, _estrés_.

3. **Time**: smartwatch con el mismo propósito.

4. **Spring**: botella de agua que recopila datos de que tanta agua se toma en el día para _recopilar datos sobre tu hidratación_.

5. **Membresía bellabeat**: Acceso 24/7 sobre orientación personalizada sobre temas de nutrición, actividad física, sueño, salud, bellaza y __mindfullnes__.


### 1.4 Tarea Empresarial
<ins>CONSIGNA: </ins>Analizar el uso de gadgets de usuarios que **NO** son de bellabeats para aplicar este conocimiento
en la empresa y finalmente presentarlo.

	Puntos clave:
		
		1. Encontrar la tendencias de uso de los gadgets de los usuarios de otras aplicaciones.
		
		2. Buscar la manera de usar estas tendencias para los usuarios de Bellabeat.
		
		3. Lograr que estas tendencias ayuden a influir en la estrategia de marketing de bellabeat


# 2. Preparación de datos

### Justificación de uso del dataset
Primeramente se usarán datos públicos que exploren los **hábitos cotidianos de los usuarios de dispositivos inteligentes**, estos datos serán sacados  de __Kaggle__, más específicamente del dataset [FitBit Fitness Tracker Data](https://www.kaggle.com/datasets/arashnic/fitbit).

Este conjunto de datos de Kaggle contiene el seguimiento de la actividad física personal en treinta usuarios de Fitbit. Treinta usuarios elegibles de Fitbit prestaron su consentimiento para el envío de datos personales de seguimiento que incluyen rendimiento de la actividad física en minutos, ritmo cardíaco y monitoreo del sueño. Incluye información sobre la actividad diaria, pasos y ritmo cardíaco que se puede usar para explorar los hábitos de los usuarios.

Del Dataset original, usaremos solamente las Base de datos que a primera vista parezcan que puedan ayudarnos
a resolver nuestra tarea empresarial, los cuales son:

  1. **dailyActivity_merged.csv** para analizar el registro de actividad diaria
  
  2. **hourlyCalories_merged.csv** para observar cuál es momento del día donde se queman más calorias y podría estar relacionado con la actividad diaria.
  
  3. **hourlyIntensities_merged.csv** para observar cuál es momento del día donde el cuerpo tiene la mayor intensidad en sus movimientos, lo que podría estar relacionado con los puntos anteriores.
  
  4. **sleepDay_merged.csv** para analizar hábitos de sueño.
  
  5. **weightLogInfo_merged.csv** para analizar el seguimiento de peso de los usuarios.
  
### Cargando las paqueterías para análisis de datos
```{r}
library(ggplot2)
library(tidyr)
library(readr)
library(dplyr)
library(skimr)
library(here)
library(janitor)
library(lubridate)
```

### Cargando las bases de datos correspondiantes
```{r}
setwd("/home/fabian/R/proyectos/analisis-bellabeat/datasets")
act_diaria <- read.csv("dailyActivity_merged.csv")
calorias <- read.csv("hourlyCalories_merged.csv")
intensidad <- read.csv("hourlyIntensities_merged.csv")
tiempo_sueno <- read.csv ("sleepDay_merged.csv")
track_peso <- read.csv("weightLogInfo_merged.csv")

```

### 2.1 Pre-exploración de datos
Lo primero que haremos es visualizar el panorama general de los marcos de datos con los que estamos trabajando, los ordenaremos y filtraremos con
el propósito de obtener un subconjunto de datos más manejable para nuestro análisis. Más adelante transforaremos datos para garantizar la integridad de los datos y proceder con el análisis.

```{r}
glimpse(act_diaria)
Sub_act_diaria <- act_diaria %>%
  mutate(ActivityDate = mdy(ActivityDate)) %>%
  arrange(-Id,ActivityDate) %>%
  filter(TotalSteps != 0) %>%
  select(-LoggedActivitiesDistance)
head(Sub_act_diaria,50)
```


- [ ]  A primera vista podemos observar que la integridad de los datos de la BD de act_diaria es buena, solamente se que mutó la variable _ActivityDate_ de chr a date y más adelante en la limpeiza de datos _id_ de dbl a int.

- [ ] Otra de las cosas importantes que pude notar es que hay días dónde ciertos usuarios parece ser que no usan los gadgets y por lo tanto esto en un futuro puede evolucionar en un sezgo para el análisis, por eso es importante filtrar esos valores desde esta etapa de preparación de datos. 
- [ ] Proseguiré a hacer el mismo análisis exploratorio con las demás BD de una manera más ágil.



```{r}
glimpse(calorias)
sub_calorias <- calorias %>%
  mutate(ActivityHour = mdy_hms(ActivityHour, tz = "UTC")) %>%
  group_by(Id) %>%
  summarize(total_calories_per_month = sum(Calories), avg_month = mean(Calories), max_cal_burn = max(Calories), min_cal_burn = min(Calories))
print(sub_calorias)
```

- [ ]  Hemos modificado la variable _ActivityHour_ para que sea un tipo de dato _date_. Falta modificar el valor de Id para que sea Int.
- [ ]  Hicimos los **estadísticos básicos** para entender mejor a nuestra población de usuarios y poder comparar el gasto calórico de cada usuario
- [ ]  Más adelante en el análisis si quisieramos ver tendencias diarias generales, agruparíamos por **date**; si buscamos patrones dentro del día, agruparía por **hour**; Si quisiera saber cómo se comportan los usuarios en diferentes horarios, agrupa por **user_id y hour**. Solo es cuestión de revisar que enfoque se adapata mejor en la resolución de la tarea empresarial y no perder en enfoque aunque los datos parezcan muy interesnates.

```{r}
sub_intensidad <- intensidad %>%
  mutate(ActivityHour = mdy_hms(ActivityHour, tz = "UTC"))
head(sub_intensidad)
```
```{r}
sub_tiempo_sueno <- tiempo_sueno %>%
  mutate(SleepDay = mdy_hms(SleepDay, tz = "UTC")) %>%
  arrange(Id) %>%
  mutate(Difsueno = TotalTimeInBed - TotalMinutesAsleep)
head(sub_tiempo_sueno,150)

```

```{r}
sub_track_peso <- track_peso %>%
  mutate(Date = mdy_hms(Date, tz = "UTC")) %>%
  arrange(Id) %>%
  select(-Fat,-LogId)
head(sub_track_peso)
```

Con esto finalizamos la preparación de datos. La siguiente fase se tratará de garantizar que los datos esten limpios, integros y listos para analizar.

# 3. Limpieza de datos

  **Tareas específicas  a realizar en nuestra limpieza:**
  
    1. Verificar si hay errores en los datos.
    2. Transformar los datos para trabajar con ellos eficazmente.
    3. Documentación de todas las limpiezas y manipulaciones de datos

``` {r}
#para Actividad diaria
act_diaria_limp <- Sub_act_diaria %>%
  rename_with(tolower) %>%
  clean_names() %>%
  mutate(distanciatotal = veryactivedistance +  moderatelyactivedistance + lightactivedistance +sedentaryactivedistance, comparar = distanciatotal == totaldistance, error_absoluto = abs(totaldistance - distanciatotal), minutosactivos = veryactiveminutes + fairlyactiveminutes + lightlyactiveminutes + sedentaryminutes)
#Error Absoluto Promedio
mae <- mean(act_diaria_limp$error_absoluto)
print(mae)

head(act_diaria_limp,200)
 #%>%
  #filter(comparar == TRUE)
conteo_errores <- act_diaria_limp %>%
  summarise(conteo_errores = sum(comparar == FALSE))
show(conteo_errores)
```
**Haré una pequeña pausa para explicar lo que está ocurriendo en la limpieza de la Actividad física diaria.**

- Al sumar las categorías de intensidad en las que se mueve el usuario con respecto a la distancias recorridas en cada una de ellas, podemos observar que si se comparan con la variable totaldistance los valores no coiciden en todos los casos, reconociendo un conteo total de **636** errores de trackeo de los gadgets.
- Un MAE de 0.0856 indica que, en promedio, la diferencia entre TotalDistance y la suma de las distancias por intensidad es 0.0856 unidades (ya sean kilómetros, millas, metros, etc.).
- El error es pequeño, lo que sugiere que las diferencias podrían deberse a redondeo o pequeños errores de trackeo, pero en la mayoría de los casos no afectaría mucho el análisis. Por lo tanto se a tomado la decisión de **NO FILTRAR LOS DATOS.**

```{r}
#calorias
calorias_limp <- sub_calorias %>%
  rename_with(tolower) %>%
  clean_names() %>%
  mutate (cal_per_day = total_calories_per_month/31 )
show(calorias_limp)

```
- Como **NOTA** tengo que agregar que en el analisis problamente tendremos que buscar en que momento del día los usuarios queman más o menos calorías, pero hasta el momento la limpiza va excelente.

```{r}
#Intensidad
intensidad_limp <- sub_intensidad %>%
  rename_with(tolower) %>%
  clean_names() 

#Sueno
 tiempo_sueno_limp <- sub_tiempo_sueno  %>%
  rename_with(tolower) %>%
  clean_names()
 #peso
track_peso_limp <- sub_track_peso %>%
  rename_with(tolower) %>%
  clean_names()
```

- Con esto finalizamos la limpieza de datos.

# 4. Análisis de datos
Ahora que los datos están almacenados adecuadamente y listos para el análisis, empiezaremos a ponerlos en funcionamiento.

  **Tareas específicas  a realizar en nuestro análisis:**
  
    1. Realiza cálculos.
    2. Identifica tendencias y relaciones, así como insights de alto valor.
    3. Logra que estos conocimientos para respondan a la pregunta empresarial.
